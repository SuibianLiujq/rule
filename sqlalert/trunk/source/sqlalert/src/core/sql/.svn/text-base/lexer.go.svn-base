// File: lexer.go
//
// This file implements the SQL lexer.
//
// Copyright (C) 2017 Yun Li Lai, Inc. All Rights Reserved.
// Written by ZHANG Li Dan <lidan.zhang@clearclouds-global.com>.
package sql

import (
	"core/scanner"
	"fmt"
	"strings"
)

// All SQL keywords.
var g_keywords = map[string]struct {
	ytype int
	ttype TokenType
	value interface{}
}{
	"true":  {Y_BOOL, T_BOOL, true},
	"false": {Y_BOOL, T_BOOL, false},
	"null":  {Y_NULL, T_NULL, nil},

	"and": {Y_AND, T_AND, nil},
	"or":  {Y_OR, T_OR, nil},
	"not": {Y_NOT, T_NOT, nil},

	"select": {Y_SELECT, T_ILL, nil},
	"from":   {Y_FROM, T_ILL, nil},
	"where":  {Y_WHERE, T_ILL, nil},
	"group":  {Y_GROUP, T_ILL, nil},
	"order":  {Y_ORDER, T_ILL, nil},
	"limit":  {Y_LIMIT, T_ILL, nil},
	"having": {Y_HAVING, T_ILL, nil},
	"unique": {Y_UNIQUE, T_ILL, nil},
	"by":     {Y_BY, T_ILL, nil},
	"as":     {Y_AS, T_ILL, nil},
	"desc":   {Y_DESC, T_ILL, nil},
	"asc":    {Y_ASC, T_ILL, nil},
	"in":     {Y_IN, T_ILL, nil},
}

// All SQL operators.
var g_operators = map[int]struct {
	ytype int
	ttype TokenType
}{
	'+': {'+', T_ADD},
	'-': {'-', T_SUB},
	'*': {'*', T_MUL},
	'/': {'/', T_DIV},
	'%': {'%', T_MOD},
	'<': {'<', T_LT},
	'>': {'>', T_GT},
	'?': {'?', T_ILL},
	':': {':', T_ILL},
	';': {';', T_ILL},
	',': {',', T_ILL},
	'(': {'(', T_ILL},
	')': {')', T_ILL},
	'[': {'[', T_ILL},
	']': {']', T_ILL},
	'{': {'{', T_ILL},
	'}': {'}', T_ILL},
	'$': {'$', T_ILL},

	'=': {Y_EQ, T_EQ},

	scanner.T_EQ:  {Y_EQ, T_EQ},
	scanner.T_NE:  {Y_NE, T_NE},
	scanner.T_LE:  {Y_LE, T_LE},
	scanner.T_GE:  {Y_GE, T_GE},
	scanner.T_AND: {Y_AND, T_AND},
	scanner.T_OR:  {Y_OR, T_OR},
	scanner.T_NOT: {Y_NOT, T_NOT},
}

// All SQL values.
var g_values = map[int]int{
	scanner.T_STR:   Y_STR,
	scanner.T_INT:   Y_INT,
	scanner.T_FLOAT: Y_FLOAT,
}

// Lexer - SQL lexer.
//
// @scanner: Scanner instance.
// @token:   Top-level token generated by goyacc.
// @errMsg:  Error message.
type Lexer struct {
	scanner *scanner.Scanner
	token   Token
	errMsg  string
}

// Init() - Initialize the Lexer instance.
//
// @src: Input byte stream.
func (this *Lexer) Init(src []byte, name string) (*Lexer, error) {
	s, err := scanner.New(src, name)
	if err != nil {
		return nil, err
	}

	this.scanner, this.token, this.errMsg = s, nil, ""
	return this, nil
}

// Lex() - Scan input bytes and return an token.
//
// @lval: Argument of lexer (given by goyacc).
func (this *Lexer) Lex(lval *yySymType) int {
	if this.scanner.GotEOF {
		return 0
	}

	token := Y_ERR
	if !this.scanner.GotError {
		switch t, v := this.scanner.Scan(); t {
		case scanner.T_EOF:
			token = 0
		case scanner.T_ILL:
			if this.scanner.GotError {
				this.Error(this.scanner.Error)
			}
		default:
			token = this.translate(t, v, lval)
		}
	}

	//	fmt.Println("token =", token, lval.operator.Name(), lval.value)
	return token
}

// Error() - Error handler.
//
// @msg: Error message.
//
// This function handle the goyacc errors.
func (this *Lexer) Error(msg string) {
	msg = fmt.Sprintf("SQL %s in line %d", msg, this.scanner.LineNum)
	this.errMsg = msg
}

// translate() - Translate scanner tokens to SQL yacc tokens.
//
// @t:    Scanner token type.
// @v:    Scanner token value.
// @lval: Argument of lexer (given by goyacc).
func (this *Lexer) translate(t int, v interface{}, lval *yySymType) int {
	switch t {
	case scanner.T_IDENT:
		key := strings.ToLower(v.(string))
		if item, ok := g_keywords[key]; ok {
			lval.operator, lval.value = item.ttype, item.value
			return item.ytype
		}

		lval.operator, lval.value = T_ILL, v
		return Y_IDENT

	case scanner.T_STR, scanner.T_INT, scanner.T_FLOAT:
		lval.operator, lval.value = T_ILL, v
		return g_values[t]

	default:
		if item, ok := g_operators[t]; ok {
			lval.operator, lval.value = item.ttype, v
			return item.ytype
		}
	}

	return Y_ERR
}

// setToken() - Set SQL token to Lexer.
//
// @lexer: Instance of Lexer.
// @token: SQL token.
func setToken(lexer interface{}, token Token) {
	lexer.(*Lexer).token = token
}
